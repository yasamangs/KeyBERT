{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yasaman/anaconda3/envs/NLP/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from keybert import KeyBERT\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_boost_values = [0.1, 0.2, 0.3, 0.4]\n",
    "allowed_pos_sets = [\n",
    "    {\"NOUN\", \"PROPN\", \"ADJ\"},\n",
    "    {\"NOUN\", \"PROPN\"},\n",
    "    {\"NOUN\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_filter(keywords, allowed_pos, nlp):\n",
    "    filtered = []\n",
    "    for kw, score in keywords:\n",
    "        doc = nlp(kw)\n",
    "        if all(token.pos_ in allowed_pos for token in doc):\n",
    "            filtered.append((kw, score))\n",
    "    return filtered\n",
    "\n",
    "def entity_boost_func(keywords, doc_text, nlp, boost_value):\n",
    "    doc = nlp(doc_text)\n",
    "    entities = set(ent.text for ent in doc.ents)\n",
    "    boosted = []\n",
    "    for kw, score in keywords:\n",
    "        if kw in entities:\n",
    "            boosted.append((kw, score + boost_value))\n",
    "        else:\n",
    "            boosted.append((kw, score))\n",
    "    return boosted\n",
    "\n",
    "def advanced_postprocess(keywords, doc_text, nlp, allowed_pos, boost_value):\n",
    "    keywords = entity_boost_func(keywords, doc_text, nlp, boost_value)\n",
    "    keywords = pos_filter(keywords, allowed_pos, nlp)\n",
    "    return keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_results(results_post, gold_keywords):\n",
    "    # Compute average exact precision and partial match precision\n",
    "    exact_scores = []\n",
    "    partial_scores = []\n",
    "    for pred, gold in zip(results_post, gold_keywords):\n",
    "        pred_set = set(pred)\n",
    "        gold_set = set(gold)\n",
    "        exact = len(pred_set & gold_set) / len(pred_set) if pred_set else 0\n",
    "        partial = sum(1 for p in pred if any(p in g or g in p for g in gold)) / len(pred) if pred else 0\n",
    "        exact_scores.append(exact)\n",
    "        partial_scores.append(partial)\n",
    "    return sum(exact_scores)/len(exact_scores), sum(partial_scores)/len(partial_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"all-MiniLM-L12-v2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 500N Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# read docs and gold keywords   \n",
    "\n",
    "docs_dir = os.path.join(\"500N-KPCrowd-v1.1\", \"500N-KPCrowd-v1.1/docsutf8\")\n",
    "keys_dir = os.path.join(\"500N-KPCrowd-v1.1\", \"500N-KPCrowd-v1.1/keys\")\n",
    "doc_files = sorted(os.listdir(docs_dir))\n",
    "key_files = sorted(os.listdir(keys_dir))\n",
    "docs = []\n",
    "gold_keywords = [] \n",
    "for doc_file, key_file in zip(doc_files, key_files):\n",
    "    with open(os.path.join(docs_dir, doc_file), encoding='utf-8') as f:\n",
    "        docs.append(f.read())\n",
    "    with open(os.path.join(keys_dir, key_file), encoding='utf-8') as f:\n",
    "        gold_keywords.append([line.strip().lower() for line in f if line.strip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Postprocess tuning using mmr eb=0.1 pos={'ADJ', 'PROPN', 'NOUN'}: 100%|██████████| 500/500 [07:02<00:00,  1.18it/s]\n",
      "Postprocess tuning using mmr eb=0.1 pos={'PROPN', 'NOUN'}: 100%|██████████| 500/500 [06:36<00:00,  1.26it/s]\n",
      "Postprocess tuning using mmr eb=0.1 pos={'NOUN'}: 100%|██████████| 500/500 [05:21<00:00,  1.56it/s]\n",
      "Postprocess tuning using mmr eb=0.2 pos={'ADJ', 'PROPN', 'NOUN'}: 100%|██████████| 500/500 [05:23<00:00,  1.55it/s]\n",
      "Postprocess tuning using mmr eb=0.2 pos={'PROPN', 'NOUN'}: 100%|██████████| 500/500 [05:09<00:00,  1.62it/s]\n",
      "Postprocess tuning using mmr eb=0.2 pos={'NOUN'}: 100%|██████████| 500/500 [05:09<00:00,  1.61it/s]\n",
      "Postprocess tuning using mmr eb=0.3 pos={'ADJ', 'PROPN', 'NOUN'}: 100%|██████████| 500/500 [05:09<00:00,  1.62it/s]\n",
      "Postprocess tuning using mmr eb=0.3 pos={'PROPN', 'NOUN'}: 100%|██████████| 500/500 [05:09<00:00,  1.61it/s]\n",
      "Postprocess tuning using mmr eb=0.3 pos={'NOUN'}: 100%|██████████| 500/500 [06:51<00:00,  1.22it/s]\n",
      "Postprocess tuning using mmr eb=0.4 pos={'ADJ', 'PROPN', 'NOUN'}: 100%|██████████| 500/500 [17:18<00:00,  2.08s/it]\n",
      "Postprocess tuning using mmr eb=0.4 pos={'PROPN', 'NOUN'}: 100%|██████████| 500/500 [11:13<00:00,  1.35s/it] \n",
      "Postprocess tuning using mmr eb=0.4 pos={'NOUN'}: 100%|██████████| 500/500 [06:00<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Postprocess using mmr Exact Precision: 0.05439999999999997 Params: (0.1, {'ADJ', 'PROPN', 'NOUN'})\n",
      "Best Postprocess using mmr Partial Precision: 0.8235333333333336 Params: (0.1, {'ADJ', 'PROPN', 'NOUN'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_exact_mmr  = 0\n",
    "best_partial_mmr = 0\n",
    "best_params_exact_mmr = None\n",
    "best_params_partial_mmr = None\n",
    "\n",
    "for entity_boost, allowed_pos in itertools.product(entity_boost_values, allowed_pos_sets):\n",
    "    kw_model = KeyBERT(model_name)\n",
    "    results_post = []\n",
    "    for doc in tqdm(docs, desc=f\"Postprocess tuning using mmr eb={entity_boost} pos={allowed_pos}\"):\n",
    "        kws_post = kw_model.extract_keywords(\n",
    "            doc, top_n=5,\n",
    "            keyphrase_ngram_range=(1, 3),\n",
    "            use_mmr=True,\n",
    "            nr_candidates=5,\n",
    "            diversity=0.3,\n",
    "            postprocess=lambda kws, doc=doc: advanced_postprocess(kws, doc, nlp, allowed_pos, entity_boost)\n",
    "        )\n",
    "        kws_post = [kw for kw, _ in kws_post]\n",
    "        results_post.append(kws_post)\n",
    "    exact_mmr, partial_mmr = evaluate_results(results_post, gold_keywords)\n",
    "    if exact_mmr > best_exact_mmr:\n",
    "        best_exact_mmr = exact_mmr\n",
    "        best_params_exact_mmr = (entity_boost, allowed_pos)\n",
    "    if partial_mmr > best_partial_mmr:\n",
    "        best_partial_mmr = partial_mmr\n",
    "        best_params_partial_mmr = (entity_boost, allowed_pos)\n",
    "\n",
    "print(\"Best Postprocess using mmr Exact Precision:\", best_exact_mmr, \"Params:\", best_params_exact_mmr)\n",
    "print(\"Best Postprocess using mmr Partial Precision:\", best_partial_mmr, \"Params:\", best_params_partial_mmr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Postprocess tuning using maxsum eb=0.1 pos={'ADJ', 'PROPN', 'NOUN'}: 100%|██████████| 500/500 [04:04<00:00,  2.05it/s]\n",
      "Postprocess tuning using maxsum eb=0.1 pos={'PROPN', 'NOUN'}: 100%|██████████| 500/500 [04:14<00:00,  1.96it/s]\n",
      "Postprocess tuning using maxsum eb=0.1 pos={'NOUN'}: 100%|██████████| 500/500 [04:14<00:00,  1.97it/s]\n",
      "Postprocess tuning using maxsum eb=0.2 pos={'ADJ', 'PROPN', 'NOUN'}: 100%|██████████| 500/500 [04:59<00:00,  1.67it/s]\n",
      "Postprocess tuning using maxsum eb=0.2 pos={'PROPN', 'NOUN'}: 100%|██████████| 500/500 [04:38<00:00,  1.79it/s]\n",
      "Postprocess tuning using maxsum eb=0.2 pos={'NOUN'}: 100%|██████████| 500/500 [03:54<00:00,  2.14it/s]\n",
      "Postprocess tuning using maxsum eb=0.3 pos={'ADJ', 'PROPN', 'NOUN'}: 100%|██████████| 500/500 [03:59<00:00,  2.09it/s]\n",
      "Postprocess tuning using maxsum eb=0.3 pos={'PROPN', 'NOUN'}: 100%|██████████| 500/500 [05:28<00:00,  1.52it/s]\n",
      "Postprocess tuning using maxsum eb=0.3 pos={'NOUN'}: 100%|██████████| 500/500 [03:56<00:00,  2.11it/s]\n",
      "Postprocess tuning using maxsum eb=0.4 pos={'ADJ', 'PROPN', 'NOUN'}: 100%|██████████| 500/500 [04:46<00:00,  1.74it/s]\n",
      "Postprocess tuning using maxsum eb=0.4 pos={'PROPN', 'NOUN'}: 100%|██████████| 500/500 [05:01<00:00,  1.66it/s]\n",
      "Postprocess tuning using maxsum eb=0.4 pos={'NOUN'}: 100%|██████████| 500/500 [05:18<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Postprocess using maxsum Exact Precision: 0.16536666666666686 Params: (0.1, {'ADJ', 'PROPN', 'NOUN'})\n",
      "Best Postprocess using maxsum Partial Precision: 0.8241666666666669 Params: (0.1, {'ADJ', 'PROPN', 'NOUN'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_exact_maxsum  = 0\n",
    "best_partial_maxsum = 0\n",
    "best_params_exact_maxsum = None\n",
    "best_params_partial_maxsum = None\n",
    "\n",
    "for entity_boost, allowed_pos in itertools.product(entity_boost_values, allowed_pos_sets):\n",
    "    kw_model = KeyBERT(model_name)\n",
    "    results_post = []\n",
    "    for doc in tqdm(docs, desc=f\"Postprocess tuning using maxsum eb={entity_boost} pos={allowed_pos}\"):\n",
    "        kws_post = kw_model.extract_keywords(\n",
    "            doc, top_n=5,\n",
    "            keyphrase_ngram_range=(1, 2),\n",
    "            use_maxsum=True,\n",
    "            nr_candidates=5,\n",
    "            postprocess=lambda kws, doc=doc: advanced_postprocess(kws, doc, nlp, allowed_pos, entity_boost)\n",
    "        )\n",
    "        kws_post = [kw for kw, _ in kws_post]\n",
    "        results_post.append(kws_post)\n",
    "    exact_maxsum, partial_maxsum = evaluate_results(results_post, gold_keywords)\n",
    "    if exact_maxsum > best_exact_maxsum:\n",
    "        best_exact_maxsum = exact_maxsum\n",
    "        best_params_exact_maxsum = (entity_boost, allowed_pos)\n",
    "    if partial_maxsum > best_partial_maxsum:\n",
    "        best_partial_maxsum = partial_maxsum\n",
    "        best_params_partial_maxsum = (entity_boost, allowed_pos)\n",
    "\n",
    "print(\"Best Postprocess using maxsum Exact Precision:\", best_exact_maxsum, \"Params:\", best_params_exact_maxsum)\n",
    "print(\"Best Postprocess using maxsum Partial Precision:\", best_partial_maxsum, \"Params:\", best_params_partial_maxsum)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SemEval 2017 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# read docs and gold keywords   \n",
    "\n",
    "docs_dir = os.path.join(\"SemEval2017\", \"docsutf8\")\n",
    "keys_dir = os.path.join(\"SemEval2017\", \"keys\")\n",
    "doc_files = sorted(os.listdir(docs_dir))\n",
    "key_files = sorted(os.listdir(keys_dir))\n",
    "docs = []\n",
    "gold_keywords = [] \n",
    "for doc_file, key_file in zip(doc_files, key_files):\n",
    "    with open(os.path.join(docs_dir, doc_file), encoding='utf-8') as f:\n",
    "        docs.append(f.read())\n",
    "    with open(os.path.join(keys_dir, key_file), encoding='utf-8') as f:\n",
    "        gold_keywords.append([line.strip().lower() for line in f if line.strip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Postprocess tuning using mmr eb=0.1 pos={'PROPN', 'NOUN', 'ADJ'}: 100%|██████████| 493/493 [03:39<00:00,  2.24it/s]\n",
      "Postprocess tuning using mmr eb=0.1 pos={'PROPN', 'NOUN'}: 100%|██████████| 493/493 [02:49<00:00,  2.90it/s]\n",
      "Postprocess tuning using mmr eb=0.1 pos={'NOUN'}: 100%|██████████| 493/493 [02:50<00:00,  2.89it/s]\n",
      "Postprocess tuning using mmr eb=0.2 pos={'PROPN', 'NOUN', 'ADJ'}: 100%|██████████| 493/493 [03:20<00:00,  2.45it/s]\n",
      "Postprocess tuning using mmr eb=0.2 pos={'PROPN', 'NOUN'}: 100%|██████████| 493/493 [03:03<00:00,  2.69it/s]\n",
      "Postprocess tuning using mmr eb=0.2 pos={'NOUN'}: 100%|██████████| 493/493 [02:50<00:00,  2.89it/s]\n",
      "Postprocess tuning using mmr eb=0.3 pos={'PROPN', 'NOUN', 'ADJ'}: 100%|██████████| 493/493 [02:48<00:00,  2.92it/s]\n",
      "Postprocess tuning using mmr eb=0.3 pos={'PROPN', 'NOUN'}: 100%|██████████| 493/493 [02:57<00:00,  2.79it/s]\n",
      "Postprocess tuning using mmr eb=0.3 pos={'NOUN'}: 100%|██████████| 493/493 [02:57<00:00,  2.77it/s]\n",
      "Postprocess tuning using mmr eb=0.4 pos={'PROPN', 'NOUN', 'ADJ'}: 100%|██████████| 493/493 [02:47<00:00,  2.95it/s]\n",
      "Postprocess tuning using mmr eb=0.4 pos={'PROPN', 'NOUN'}: 100%|██████████| 493/493 [02:46<00:00,  2.96it/s]\n",
      "Postprocess tuning using mmr eb=0.4 pos={'NOUN'}: 100%|██████████| 493/493 [03:24<00:00,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Postprocess using mmr Exact Precision: 0.1504394861392834 Params: (0.1, {'PROPN', 'NOUN', 'ADJ'})\n",
      "Best Postprocess using mmr Partial Precision: 0.6712305611899937 Params: (0.1, {'PROPN', 'NOUN', 'ADJ'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_exact_mmr  = 0\n",
    "best_partial_mmr = 0\n",
    "best_params_exact_mmr = None\n",
    "best_params_partial_mmr = None\n",
    "\n",
    "for entity_boost, allowed_pos in itertools.product(entity_boost_values, allowed_pos_sets):\n",
    "    kw_model = KeyBERT(model_name)\n",
    "    results_post = []\n",
    "    for doc in tqdm(docs, desc=f\"Postprocess tuning using mmr eb={entity_boost} pos={allowed_pos}\"):\n",
    "        kws_post = kw_model.extract_keywords(\n",
    "            doc, top_n=5,\n",
    "            keyphrase_ngram_range=(1, 3),\n",
    "            use_mmr=True,\n",
    "            nr_candidates=5,\n",
    "            diversity=0.3,\n",
    "            postprocess=lambda kws, doc=doc: advanced_postprocess(kws, doc, nlp, allowed_pos, entity_boost)\n",
    "        )\n",
    "        kws_post = [kw for kw, _ in kws_post]\n",
    "        results_post.append(kws_post)\n",
    "    exact_mmr, partial_mmr = evaluate_results(results_post, gold_keywords)\n",
    "    if exact_mmr > best_exact_mmr:\n",
    "        best_exact_mmr = exact_mmr\n",
    "        best_params_exact_mmr = (entity_boost, allowed_pos)\n",
    "    if partial_mmr > best_partial_mmr:\n",
    "        best_partial_mmr = partial_mmr\n",
    "        best_params_partial_mmr = (entity_boost, allowed_pos)\n",
    "\n",
    "print(\"Best Postprocess using mmr Exact Precision:\", best_exact_mmr, \"Params:\", best_params_exact_mmr)\n",
    "print(\"Best Postprocess using mmr Partial Precision:\", best_partial_mmr, \"Params:\", best_params_partial_mmr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Postprocess tuning using maxsum eb=0.1 pos={'PROPN', 'NOUN', 'ADJ'}: 100%|██████████| 493/493 [02:05<00:00,  3.94it/s]\n",
      "Postprocess tuning using maxsum eb=0.1 pos={'PROPN', 'NOUN'}: 100%|██████████| 493/493 [02:02<00:00,  4.02it/s]\n",
      "Postprocess tuning using maxsum eb=0.1 pos={'NOUN'}: 100%|██████████| 493/493 [02:01<00:00,  4.07it/s]\n",
      "Postprocess tuning using maxsum eb=0.2 pos={'PROPN', 'NOUN', 'ADJ'}: 100%|██████████| 493/493 [02:01<00:00,  4.05it/s]\n",
      "Postprocess tuning using maxsum eb=0.2 pos={'PROPN', 'NOUN'}: 100%|██████████| 493/493 [01:58<00:00,  4.15it/s]\n",
      "Postprocess tuning using maxsum eb=0.2 pos={'NOUN'}: 100%|██████████| 493/493 [02:04<00:00,  3.95it/s]\n",
      "Postprocess tuning using maxsum eb=0.3 pos={'PROPN', 'NOUN', 'ADJ'}: 100%|██████████| 493/493 [02:05<00:00,  3.92it/s]\n",
      "Postprocess tuning using maxsum eb=0.3 pos={'PROPN', 'NOUN'}: 100%|██████████| 493/493 [02:05<00:00,  3.92it/s]\n",
      "Postprocess tuning using maxsum eb=0.3 pos={'NOUN'}: 100%|██████████| 493/493 [02:06<00:00,  3.90it/s]\n",
      "Postprocess tuning using maxsum eb=0.4 pos={'PROPN', 'NOUN', 'ADJ'}: 100%|██████████| 493/493 [02:04<00:00,  3.96it/s]\n",
      "Postprocess tuning using maxsum eb=0.4 pos={'PROPN', 'NOUN'}: 100%|██████████| 493/493 [02:02<00:00,  4.03it/s]\n",
      "Postprocess tuning using maxsum eb=0.4 pos={'NOUN'}: 100%|██████████| 493/493 [02:08<00:00,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Postprocess using maxsum Exact Precision: 0.2392832995267073 Params: (0.1, {'PROPN', 'NOUN', 'ADJ'})\n",
      "Best Postprocess using maxsum Partial Precision: 0.7591615956727529 Params: (0.1, {'PROPN', 'NOUN', 'ADJ'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_exact_maxsum  = 0\n",
    "best_partial_maxsum = 0\n",
    "best_params_exact_maxsum = None\n",
    "best_params_partial_maxsum = None\n",
    "\n",
    "for entity_boost, allowed_pos in itertools.product(entity_boost_values, allowed_pos_sets):\n",
    "    kw_model = KeyBERT(model_name)\n",
    "    results_post = []\n",
    "    for doc in tqdm(docs, desc=f\"Postprocess tuning using maxsum eb={entity_boost} pos={allowed_pos}\"):\n",
    "        kws_post = kw_model.extract_keywords(\n",
    "            doc, top_n=5,\n",
    "            keyphrase_ngram_range=(1, 2),\n",
    "            use_maxsum=True,\n",
    "            nr_candidates=5,\n",
    "            postprocess=lambda kws, doc=doc: advanced_postprocess(kws, doc, nlp, allowed_pos, entity_boost)\n",
    "        )\n",
    "        kws_post = [kw for kw, _ in kws_post]\n",
    "        results_post.append(kws_post)\n",
    "    exact_maxsum, partial_maxsum = evaluate_results(results_post, gold_keywords)\n",
    "    if exact_maxsum > best_exact_maxsum:\n",
    "        best_exact_maxsum = exact_maxsum\n",
    "        best_params_exact_maxsum = (entity_boost, allowed_pos)\n",
    "    if partial_maxsum > best_partial_maxsum:\n",
    "        best_partial_maxsum = partial_maxsum\n",
    "        best_params_partial_maxsum = (entity_boost, allowed_pos)\n",
    "\n",
    "print(\"Best Postprocess using maxsum Exact Precision:\", best_exact_maxsum, \"Params:\", best_params_exact_maxsum)\n",
    "print(\"Best Postprocess using maxsum Partial Precision:\", best_partial_maxsum, \"Params:\", best_params_partial_maxsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
