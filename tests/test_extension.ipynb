{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yasaman/anaconda3/envs/NLP/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from keybert import KeyBERT\n",
    "import os\n",
    "import zipfile\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy and define post-processing functions\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Process Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_filter(keywords):\n",
    "    filtered = []\n",
    "    for kw, score in keywords:\n",
    "        doc = nlp(kw)\n",
    "        if all(token.pos_ in {\"NOUN\", \"PROPN\", \"ADJ\"} for token in doc):\n",
    "            filtered.append((kw, score))\n",
    "    return filtered\n",
    "\n",
    "def entity_boost(keywords, text):\n",
    "    doc = nlp(text)\n",
    "    entities = set(ent.text for ent in doc.ents)\n",
    "    boosted = []\n",
    "    for kw, score in keywords:\n",
    "        if kw in entities:\n",
    "            boosted.append((kw, score + 0.2))\n",
    "        else:\n",
    "            boosted.append((kw, score))\n",
    "    return boosted\n",
    "\n",
    "\n",
    "def advanced_postprocess(keywords, doc_text, nlp):\n",
    "    keywords = entity_boost(keywords, doc_text)\n",
    "    keywords = pos_filter(keywords)\n",
    "\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function: counts both exact and partial matches\n",
    "def evaluate_results(results_post, gold_keywords):\n",
    "    precisions, recalls, f1s = [], [], []\n",
    "    for pred, gold in zip(results_post, gold_keywords):\n",
    "        pred_set = set(pred)\n",
    "        gold_set = set(gold)\n",
    "        exact_matches = set([p for p in pred_set if p in gold_set])\n",
    "        partial_matches = set([\n",
    "            p for p in pred_set\n",
    "            if any((p in g or g in p) for g in gold_set) and p not in exact_matches\n",
    "        ])\n",
    "        total_matches = len(exact_matches) + len(partial_matches)\n",
    "        precision = total_matches / len(pred) if pred else 0\n",
    "        recall = total_matches / len(gold) if gold else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) else 0\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "    avg_precision = sum(precisions) / len(precisions)\n",
    "    avg_recall = sum(recalls) / len(recalls)\n",
    "    avg_f1 = sum(f1s) / len(f1s)\n",
    "    return avg_precision, avg_recall, avg_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keybert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize KeyBERT model\n",
    "kw_model = KeyBERT()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 500N Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read docs and gold keywords   \n",
    "\n",
    "docs_dir = os.path.join(\"500N-KPCrowd-v1.1\", \"500N-KPCrowd-v1.1/docsutf8\")\n",
    "keys_dir = os.path.join(\"500N-KPCrowd-v1.1\", \"500N-KPCrowd-v1.1/keys\")\n",
    "doc_files = sorted(os.listdir(docs_dir))\n",
    "key_files = sorted(os.listdir(keys_dir))\n",
    "docs = []\n",
    "gold_keywords = [] \n",
    "for doc_file, key_file in zip(doc_files, key_files):\n",
    "    with open(os.path.join(docs_dir, doc_file), encoding='utf-8') as f:\n",
    "        docs.append(f.read())\n",
    "    with open(os.path.join(keys_dir, key_file), encoding='utf-8') as f:\n",
    "        gold_keywords.append([line.strip().lower() for line in f if line.strip()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### which post-processing function works best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [07:46<00:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Post-processing Entity Boost: Precision 0.750, Recall 0.098, F1 0.168\n",
      "With Post-processing Entity Boost: Precision 0.750, Recall 0.098, F1 0.168\n",
      "No Post-processing Pos Filter: Precision 0.750, Recall 0.098, F1 0.168\n",
      "With Post-processing Pos Filter: Precision 0.759, Recall 0.086, F1 0.149\n",
      "No Post-processing Advanced: Precision 0.750, Recall 0.098, F1 0.168\n",
      "With Post-processing Advanced: Precision 0.759, Recall 0.086, F1 0.149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract keywords with and without post-processing for the full dataset\n",
    "N = 5  # Number of keywords to extract\n",
    "results_no_entityboost = []\n",
    "results_entityboost = []\n",
    "results_no_posfilter = []\n",
    "results_posfilter = []\n",
    "results_no_advanced = []\n",
    "results_advanced = []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for doc in tqdm(docs):\n",
    "        # Entity boost postprocessing\n",
    "        kws_no_post_entityboost = [kw for kw, _ in kw_model.extract_keywords(doc, top_n=N)]\n",
    "        kws_post_entityboost = kw_model.extract_keywords(\n",
    "            doc, top_n=N,\n",
    "            postprocess=lambda kws: entity_boost(kws, doc)\n",
    "        )\n",
    "        kws_post_entityboost = [kw for kw, _ in kws_post_entityboost]\n",
    "        results_no_entityboost.append(kws_no_post_entityboost)\n",
    "        results_entityboost.append(kws_post_entityboost)\n",
    "\n",
    "        # POS filter postprocessing\n",
    "        kws_no_post_posfilter = [kw for kw, _ in kw_model.extract_keywords(doc, top_n=N)]\n",
    "        kws_post_posfilter = kw_model.extract_keywords(\n",
    "            doc, top_n=N,\n",
    "            postprocess=lambda kws: pos_filter(kws)\n",
    "        )\n",
    "        kws_post_posfilter = [kw for kw, _ in kws_post_posfilter]\n",
    "        results_no_posfilter.append(kws_no_post_posfilter)\n",
    "        results_posfilter.append(kws_post_posfilter)\n",
    "\n",
    "        # Advanced postprocessing\n",
    "        kws_no_post_advanced = [kw for kw, _ in kw_model.extract_keywords(doc, top_n=N)]\n",
    "        kws_post_advanced = kw_model.extract_keywords(\n",
    "            doc, top_n=N,\n",
    "            postprocess=lambda kws: advanced_postprocess(kws, doc, nlp)\n",
    "        )\n",
    "        kws_post_advanced = [kw for kw, _ in kws_post_advanced]\n",
    "        results_no_advanced.append(kws_no_post_advanced)\n",
    "        results_advanced.append(kws_post_advanced)\n",
    "\n",
    "    precision_entityboost, recall_entityboost, f1_entityboost = evaluate_results(results_entityboost, gold_keywords)\n",
    "    precision_no_entityboost, recall_no_entityboost, f1_no_entityboost = evaluate_results(results_no_entityboost, gold_keywords)\n",
    "    precision_posfilter, recall_posfilter, f1_posfilter = evaluate_results(results_posfilter, gold_keywords)\n",
    "    precision_no_posfilter, recall_no_posfilter, f1_no_posfilter = evaluate_results(results_no_posfilter, gold_keywords)\n",
    "    precision_advanced, recall_advanced, f1_advanced = evaluate_results(results_advanced, gold_keywords)\n",
    "    precision_no_advanced, recall_no_advanced, f1_no_advanced = evaluate_results(results_no_advanced, gold_keywords)\n",
    "\n",
    "\n",
    "    print(\"No Post-processing Entity Boost: Precision {:.3f}, Recall {:.3f}, F1 {:.3f}\".format(\n",
    "        precision_no_entityboost, recall_no_entityboost, f1_no_entityboost))\n",
    "    print(\"With Post-processing Entity Boost: Precision {:.3f}, Recall {:.3f}, F1 {:.3f}\".format(\n",
    "    precision_entityboost, recall_entityboost, f1_entityboost))\n",
    "\n",
    "\n",
    "    precision_no_posfilter, recall_no_posfilter, f1_no_posfilter = evaluate_results(results_no_posfilter, gold_keywords)\n",
    "    precision_posfilter, recall_posfilter, f1_posfilter = evaluate_results(results_posfilter, gold_keywords)\n",
    "\n",
    "    print(\"No Post-processing Pos Filter: Precision {:.3f}, Recall {:.3f}, F1 {:.3f}\".format(\n",
    "        precision_no_posfilter, recall_no_posfilter, f1_no_posfilter))\n",
    "    print(\"With Post-processing Pos Filter: Precision {:.3f}, Recall {:.3f}, F1 {:.3f}\".format(\n",
    "        precision_posfilter, recall_posfilter, f1_posfilter))\n",
    "    \n",
    "    precision_no_advanced, recall_no_advanced, f1_no_advanced = evaluate_results(results_no_advanced, gold_keywords)\n",
    "    precision_advanced, recall_advanced, f1_advanced = evaluate_results(results_advanced, gold_keywords)\n",
    "   \n",
    "\n",
    "    print(\"No Post-processing Advanced: Precision {:.3f}, Recall {:.3f}, F1 {:.3f}\".format(\n",
    "        precision_no_advanced, recall_no_advanced, f1_no_advanced))\n",
    "    print(\"With Post-processing Advanced: Precision {:.3f}, Recall {:.3f}, F1 {:.3f}\".format(\n",
    "        precision_advanced, recall_advanced, f1_advanced))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing MMR and Maxsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [05:53<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Post-processing_MMR: Precision 0.712, Recall 0.093, F1 0.159\n",
      "With Post-processing_MMR: Precision 0.733, Recall 0.078, F1 0.136\n",
      "No Post-processing_MaxSum: Precision 0.629, Recall 0.084, F1 0.143\n",
      "With Post-processing_MaxSum: Precision 0.640, Recall 0.067, F1 0.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract keywords with and without post-processing for the full dataset\n",
    "N = 5  # Number of keywords to extract\n",
    "results_no_post_mmr = []\n",
    "results_post_mmr = []\n",
    "results_no_post_maxsum = []\n",
    "results_post_maxsum = []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for doc in tqdm(docs):\n",
    "        kws_no_post_mmr = [kw for kw, _ in kw_model.extract_keywords(doc, top_n=N, use_mmr=True)]\n",
    "        kws_post_mmr = kw_model.extract_keywords(\n",
    "            doc, top_n=N,\n",
    "            postprocess=lambda kws: pos_filter(kws),\n",
    "            use_mmr=True\n",
    "        )\n",
    "        kws_post_mmr = [kw for kw, _ in kws_post_mmr]\n",
    "        results_no_post_mmr.append(kws_no_post_mmr)\n",
    "        results_post_mmr.append(kws_post_mmr)\n",
    "        kws_no_post_maxsum = [kw for kw, _ in kw_model.extract_keywords(doc, top_n=N, use_maxsum=True)]\n",
    "        kws_post_maxsum = kw_model.extract_keywords(\n",
    "            doc, top_n=N,\n",
    "            postprocess=lambda kws: pos_filter(kws),\n",
    "            use_maxsum=True\n",
    "        )\n",
    "        kws_post_maxsum = [kw for kw, _ in kws_post_maxsum]\n",
    "        results_no_post_maxsum.append(kws_no_post_maxsum)\n",
    "        results_post_maxsum.append(kws_post_maxsum)\n",
    "\n",
    "    # Evaluate and print results\n",
    "    precision_no_post_mmr, recall_no_post_mmr, f1_no_post_mmr = evaluate_results(results_no_post_mmr, gold_keywords)\n",
    "    precision_post_mmr, recall_post_mmr, f1_post_mmr = evaluate_results(results_post_mmr, gold_keywords)\n",
    "\n",
    "    print(\"No Post-processing_MMR: Precision {:.3f}, Recall {:.3f}, F1 {:.3f}\".format(\n",
    "        precision_no_post_mmr, recall_no_post_mmr, f1_no_post_mmr))\n",
    "    print(\"With Post-processing_MMR: Precision {:.3f}, Recall {:.3f}, F1 {:.3f}\".format(\n",
    "        precision_post_mmr, recall_post_mmr, f1_post_mmr))\n",
    "\n",
    "    \n",
    "    precision_no_post_maxsum, recall_no_post_maxsum, f1_no_post_maxsum = evaluate_results(results_no_post_maxsum, gold_keywords)\n",
    "    precision_post_maxsum, recall_post_maxsum, f1_post_maxsum = evaluate_results(results_post_maxsum, gold_keywords)\n",
    "\n",
    "    print(\"No Post-processing_MaxSum: Precision {:.3f}, Recall {:.3f}, F1 {:.3f}\".format(\n",
    "        precision_no_post_maxsum, recall_no_post_maxsum, f1_no_post_maxsum))\n",
    "    print(\"With Post-processing_MaxSum: Precision {:.3f}, Recall {:.3f}, F1 {:.3f}\".format(\n",
    "        precision_post_maxsum, recall_post_maxsum, f1_post_maxsum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SemEval Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# read docs and gold keywords   \n",
    "\n",
    "docs_dir = os.path.join(\"SemEval2017\", \"docsutf8\")\n",
    "keys_dir = os.path.join(\"SemEval2017\", \"keys\")\n",
    "doc_files = sorted(os.listdir(docs_dir))\n",
    "key_files = sorted(os.listdir(keys_dir))\n",
    "docs = []\n",
    "gold_keywords = [] \n",
    "for doc_file, key_file in zip(doc_files, key_files):\n",
    "    with open(os.path.join(docs_dir, doc_file), encoding='utf-8') as f:\n",
    "        docs.append(f.read())\n",
    "    with open(os.path.join(keys_dir, key_file), encoding='utf-8') as f:\n",
    "        gold_keywords.append([line.strip().lower() for line in f if line.strip()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### which post-processing function works best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 493/493 [05:10<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Post-processing Entity Boost: Precision 0.865, Recall 0.285, F1 0.415\n",
      "With Post-processing Entity Boost: Precision 0.865, Recall 0.285, F1 0.415\n",
      "No Post-processing Pos Filter: Precision 0.865, Recall 0.285, F1 0.415\n",
      "With Post-processing Pos Filter: Precision 0.872, Recall 0.246, F1 0.368\n",
      "No Post-processing Advanced: Precision 0.865, Recall 0.285, F1 0.415\n",
      "With Post-processing Advanced: Precision 0.872, Recall 0.246, F1 0.368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract keywords with and without post-processing for the full dataset\n",
    "N = 5  # Number of keywords to extract\n",
    "results_no_entityboost = []\n",
    "results_entityboost = []\n",
    "results_no_posfilter = []\n",
    "results_posfilter = []\n",
    "results_no_advanced = []\n",
    "results_advanced = []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for doc in tqdm(docs):\n",
    "        # Entity boost postprocessing\n",
    "        kws_no_post_entityboost = [kw for kw, _ in kw_model.extract_keywords(doc, top_n=N)]\n",
    "        kws_post_entityboost = kw_model.extract_keywords(\n",
    "            doc, top_n=N,\n",
    "            postprocess=lambda kws: entity_boost(kws, doc)\n",
    "        )\n",
    "        kws_post_entityboost = [kw for kw, _ in kws_post_entityboost]\n",
    "        results_no_entityboost.append(kws_no_post_entityboost)\n",
    "        results_entityboost.append(kws_post_entityboost)\n",
    "\n",
    "        # POS filter postprocessing\n",
    "        kws_no_post_posfilter = [kw for kw, _ in kw_model.extract_keywords(doc, top_n=N)]\n",
    "        kws_post_posfilter = kw_model.extract_keywords(\n",
    "            doc, top_n=N,\n",
    "            postprocess=lambda kws: pos_filter(kws)\n",
    "        )\n",
    "        kws_post_posfilter = [kw for kw, _ in kws_post_posfilter]\n",
    "        results_no_posfilter.append(kws_no_post_posfilter)\n",
    "        results_posfilter.append(kws_post_posfilter)\n",
    "\n",
    "        # Advanced postprocessing\n",
    "        kws_no_post_advanced = [kw for kw, _ in kw_model.extract_keywords(doc, top_n=N)]\n",
    "        kws_post_advanced = kw_model.extract_keywords(\n",
    "            doc, top_n=N,\n",
    "            postprocess=lambda kws: advanced_postprocess(kws, doc, nlp)\n",
    "        )\n",
    "        kws_post_advanced = [kw for kw, _ in kws_post_advanced]\n",
    "        results_no_advanced.append(kws_no_post_advanced)\n",
    "        results_advanced.append(kws_post_advanced)\n",
    "\n",
    "    precision_entityboost, recall_entityboost, f1_entityboost = evaluate_results(results_entityboost, gold_keywords)\n",
    "    precision_no_entityboost, recall_no_entityboost, f1_no_entityboost = evaluate_results(results_no_entityboost, gold_keywords)\n",
    "    precision_posfilter, recall_posfilter, f1_posfilter = evaluate_results(results_posfilter, gold_keywords)\n",
    "    precision_no_posfilter, recall_no_posfilter, f1_no_posfilter = evaluate_results(results_no_posfilter, gold_keywords)\n",
    "    precision_advanced, recall_advanced, f1_advanced = evaluate_results(results_advanced, gold_keywords)\n",
    "    precision_no_advanced, recall_no_advanced, f1_no_advanced = evaluate_results(results_no_advanced, gold_keywords)\n",
    "\n",
    "\n",
    "    print(\"No Post-processing Entity Boost: Precision {:.3f}, Recall {:.3f}, F1 {:.3f}\".format(\n",
    "        precision_no_entityboost, recall_no_entityboost, f1_no_entityboost))\n",
    "    print(\"With Post-processing Entity Boost: Precision {:.3f}, Recall {:.3f}, F1 {:.3f}\".format(\n",
    "    precision_entityboost, recall_entityboost, f1_entityboost))\n",
    "\n",
    "\n",
    "    precision_no_posfilter, recall_no_posfilter, f1_no_posfilter = evaluate_results(results_no_posfilter, gold_keywords)\n",
    "    precision_posfilter, recall_posfilter, f1_posfilter = evaluate_results(results_posfilter, gold_keywords)\n",
    "\n",
    "    print(\"No Post-processing Pos Filter: Precision {:.3f}, Recall {:.3f}, F1 {:.3f}\".format(\n",
    "        precision_no_posfilter, recall_no_posfilter, f1_no_posfilter))\n",
    "    print(\"With Post-processing Pos Filter: Precision {:.3f}, Recall {:.3f}, F1 {:.3f}\".format(\n",
    "        precision_posfilter, recall_posfilter, f1_posfilter))\n",
    "    \n",
    "    precision_no_advanced, recall_no_advanced, f1_no_advanced = evaluate_results(results_no_advanced, gold_keywords)\n",
    "    precision_advanced, recall_advanced, f1_advanced = evaluate_results(results_advanced, gold_keywords)\n",
    "   \n",
    "\n",
    "    print(\"No Post-processing Advanced: Precision {:.3f}, Recall {:.3f}, F1 {:.3f}\".format(\n",
    "        precision_no_advanced, recall_no_advanced, f1_no_advanced))\n",
    "    print(\"With Post-processing Advanced: Precision {:.3f}, Recall {:.3f}, F1 {:.3f}\".format(\n",
    "        precision_advanced, recall_advanced, f1_advanced))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing MMR and Maxsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 493/493 [04:52<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Post-processing_MMR: Precision 0.830, Recall 0.273, F1 0.398\n",
      "With Post-processing_MMR: Precision 0.841, Recall 0.233, F1 0.350\n",
      "No Post-processing_MaxSum: Precision 0.754, Recall 0.245, F1 0.357\n",
      "With Post-processing_MaxSum: Precision 0.766, Recall 0.200, F1 0.304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract keywords with and without post-processing for the full dataset\n",
    "N = 5  # Number of keywords to extract\n",
    "results_no_post_mmr = []\n",
    "results_post_mmr = []\n",
    "results_no_post_maxsum = []\n",
    "results_post_maxsum = []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for doc in tqdm(docs):\n",
    "        kws_no_post_mmr = [kw for kw, _ in kw_model.extract_keywords(doc, top_n=N, use_mmr=True)]\n",
    "        kws_post_mmr = kw_model.extract_keywords(\n",
    "            doc, top_n=N,\n",
    "            postprocess=lambda kws: pos_filter(kws),\n",
    "            use_mmr=True\n",
    "        )\n",
    "        kws_post_mmr = [kw for kw, _ in kws_post_mmr]\n",
    "        results_no_post_mmr.append(kws_no_post_mmr)\n",
    "        results_post_mmr.append(kws_post_mmr)\n",
    "        kws_no_post_maxsum = [kw for kw, _ in kw_model.extract_keywords(doc, top_n=N, use_maxsum=True)]\n",
    "        kws_post_maxsum = kw_model.extract_keywords(\n",
    "            doc, top_n=N,\n",
    "            postprocess=lambda kws: pos_filter(kws),\n",
    "            use_maxsum=True\n",
    "        )\n",
    "        kws_post_maxsum = [kw for kw, _ in kws_post_maxsum]\n",
    "        results_no_post_maxsum.append(kws_no_post_maxsum)\n",
    "        results_post_maxsum.append(kws_post_maxsum)\n",
    "\n",
    "    # Evaluate and print results\n",
    "    precision_no_post_mmr, recall_no_post_mmr, f1_no_post_mmr = evaluate_results(results_no_post_mmr, gold_keywords)\n",
    "    precision_post_mmr, recall_post_mmr, f1_post_mmr = evaluate_results(results_post_mmr, gold_keywords)\n",
    "\n",
    "    print(\"No Post-processing_MMR: Precision {:.3f}, Recall {:.3f}, F1 {:.3f}\".format(\n",
    "        precision_no_post_mmr, recall_no_post_mmr, f1_no_post_mmr))\n",
    "    print(\"With Post-processing_MMR: Precision {:.3f}, Recall {:.3f}, F1 {:.3f}\".format(\n",
    "        precision_post_mmr, recall_post_mmr, f1_post_mmr))\n",
    "\n",
    "    \n",
    "    precision_no_post_maxsum, recall_no_post_maxsum, f1_no_post_maxsum = evaluate_results(results_no_post_maxsum, gold_keywords)\n",
    "    precision_post_maxsum, recall_post_maxsum, f1_post_maxsum = evaluate_results(results_post_maxsum, gold_keywords)\n",
    "\n",
    "    print(\"No Post-processing_MaxSum: Precision {:.3f}, Recall {:.3f}, F1 {:.3f}\".format(\n",
    "        precision_no_post_maxsum, recall_no_post_maxsum, f1_no_post_maxsum))\n",
    "    print(\"With Post-processing_MaxSum: Precision {:.3f}, Recall {:.3f}, F1 {:.3f}\".format(\n",
    "        precision_post_maxsum, recall_post_maxsum, f1_post_maxsum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
